{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Search\n",
    "(Fetching and displaying yelp data)\n",
    "\n",
    "#### Web Scraping\n",
    "* Using HTTP to fetch the content of a website\n",
    "* HTTP Requests (and lifecycle)\n",
    "* RESTful APIs\n",
    "  * Authentication (OAuth)\n",
    "  * Pagination\n",
    "  * Rate limiting\n",
    "* JSON vs. HTML (and how to parse each)\n",
    "* HTML traversal (CSS selectors)\n",
    "\n",
    "#### Data Collection & Data Processing\n",
    "* Slicing data frames\n",
    "* Filtering data\n",
    "* Grouped counts\n",
    "* Joining two tables\n",
    "* NA/Null values\n",
    "\n",
    "#### Library Documentation\n",
    "For solving this part, you need to look up online documentation for the Python packages you will use:\n",
    "* Standard Library: \n",
    "  * [io](https://docs.python.org/2/library/io.html)\n",
    "  * [time](https://docs.python.org/2/library/time.html)\n",
    "  * [json](https://docs.python.org/2/library/json.html)\n",
    "* Third Party\n",
    "  * [requests](http://docs.python-requests.org/en/master/)\n",
    "  * [Beautiful Soup (version 4)](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "  * [yelp-fusion](https://www.yelp.com/developers/documentation/v3/get_started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, time, json, requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Download and return the raw HTML content of a URL\n",
    "`retrieve_html`: download and return raw HTML content of url passed as an argument\n",
    "* args: \n",
    "  * url (string)\n",
    "* returns:\n",
    "  * status_code (integer):\n",
    "  * raw_html (string): the raw html content of the response, properly encoded according to the http headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_html(url):\n",
    "  response = requests.get(url)\n",
    "  status_code = response.status_code\n",
    "  raw_html = response.text \n",
    "  return status_code, raw_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `retrieve_html`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\" class=\"story\"  xmlns:og=\"http://opengraphprotocol.org/schema/\">\n",
      "  <head>\n",
      "    <title data-rh=\"true\">YouTube’s Product Chief on Online Radicalization and Algorithmic Rabbit Holes - The New York Times</title>\n",
      "    <meta data-rh=\"true\" property=\"article:published_time\" content=\"2019-03-29T15:40:56.000Z\"/><meta data-rh=\"true\" property=\"article:modified_time\" content=\"2019-04-01T02:48:25.343Z\"/><meta data-rh=\"true\" http-equiv=\"Content-Language\" content=\"en\"/><meta data-r\n"
     ]
    }
   ],
   "source": [
    "youtube_article = retrieve_html('https://www.nytimes.com/2019/03/29/technology/youtube-online-extremism.html')\n",
    "print(youtube_article[0])\n",
    "print(youtube_article[1][:500])\n",
    "# (200, '<!DOCTYPE html>\\n<html lang=\"en\" class=\"story\" xmlns:og=\"http://opengraphprotocol.org/schema/\">\\n  <head>\\n    <title data-rh=\"true\">YouTube’s ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Store Yelp API key locally and read in API key to authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('yelp_api_key.txt', 'r') as f:\n",
    "  api_key = f.read().replace('\\n','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_api_key`: read yelp API from file\n",
    "* args:\n",
    "  * filepath (string): file containing API key\n",
    "* returns:\n",
    "  * api_key (string): api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_api_key(filepath):    \n",
    "  with open(filepath, 'r') as f:\n",
    "    return f.read().replace('\\n','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make an authenticated request to the search endpoint\n",
    "`api_get_request`: send an HTTP GET request and return a json response\n",
    "* args:\n",
    "  * url (string): API endpoint url\n",
    "  * headers (dict): A python dictionary containing HTTP headers including Authentication to be sent\n",
    "  * url_params (dict): The parameters (required and optional) supported by endpoint\n",
    "* returns:\n",
    "  * results (json): response as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_get_request(url, headers, url_params):\n",
    "  http_method = 'GET'\n",
    "  # See requests.request?\n",
    "  response = requests.get(url, params = url_params, headers = headers)\n",
    "  content_json = response.json()  \n",
    "  return content_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Get \n",
    "`location_search_params`: construct url, headers, and url parameters\n",
    "* args:\n",
    "  * api_key (string):\n",
    "  * location (string):\n",
    "  * kwargs ():\n",
    "* returns:\n",
    "  * url (string):\n",
    "  * headers (): \n",
    "  * url_parama ():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_search_params(api_key, location, **kwargs):\n",
    "\n",
    "  # What is the url endpoint for search?\n",
    "  url = 'https://api.yelp.com/v3/businesses/search'\n",
    "\n",
    "  # How is Authentication performed?\n",
    "  headers = {'Authorization': f\"Bearer {api_key}\"}\n",
    "\n",
    "  # SPACES in url is problematic. How should you handle location containing spaces?\n",
    "  location_no_space = location.replace(\" \", \"-\")\n",
    "  url_params = {'location': f\"{location_no_space}\"} \n",
    "\n",
    "  # Include keyword arguments in url_params \n",
    "  if kwargs is not None:\n",
    "    for key, value in kwargs.items():\n",
    "      #str(value).replace(\" \", \"-\")\n",
    "      url_params[key] = value\n",
    "\n",
    "  return url, headers, url_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\n",
    "`yelp_search`: \n",
    "* args:\n",
    "  * api_key (string): \n",
    "  * location ():\n",
    "  * offset ():\n",
    "* returns:\n",
    "  * response_json (json):\n",
    "  * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yelp_search(api_key, location, offset=0):\n",
    "  \"\"\"\n",
    "  Make an authenticated request to the Yelp API.\n",
    "\n",
    "  Args:\n",
    "    api_key (string): Your Yelp API Key for Authentication\n",
    "    location (string): Business Location\n",
    "    offset (int): param for pagination\n",
    "\n",
    "  Returns:\n",
    "    total (integer): total number of businesses on Yelp corresponding to the location\n",
    "    businesses (list): list of dicts representing each business\n",
    "  \"\"\"\n",
    "  url, headers, url_params = location_search_params(api_key, location, offset=0)\n",
    "\n",
    "  response_json = api_get_request(url, headers, url_params)\n",
    "  return response_json[\"total\"], list(response_json[\"businesses\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test `yelp_search`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500\n",
      "20\n",
      "['Girl & The Goat', 'Wildberry Pancakes and Cafe', 'Au Cheval', 'The Purple Pig', \"Lou Malnati's Pizzeria\", 'Art Institute of Chicago', 'Smoque BBQ', 'Cafe Ba-Ba-Reeba!', \"Bavette's Bar & Boeuf\", 'Little Goat', 'Alinea', \"Kuma's Corner - Belmont\", 'Quartino Ristorante', \"Pequod's Pizzeria\", \"Portillo's Hot Dogs\", \"Joe's Seafood, Prime Steak & Stone Crab\", 'Crisp', 'Xoco', 'Sapori Trattoria', \"Molly's Cupcakes\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "api_key = read_api_key('yelp_api_key.txt')\n",
    "num_records, data = yelp_search(api_key, 'Chicago')\n",
    "print(num_records)\n",
    "#8500\n",
    "print(len(data))\n",
    "#20\n",
    "print(list(map(lambda x: x['name'], data)))\n",
    "#['Girl & the Goat', 'Wildberry Pancakes and Cafe', 'Au Cheval', 'The Purple Pig', 'Art Institute of Chicago', 'Smoque BBQ', \"Lou Malnati's Pizzeria\", 'Alinea', \"Kuma's Corner - Belmont\", 'Little Goat Diner', \"Bavette's Bar & Boeuf\", 'Cafe Ba-Ba-Reeba!', \"Portillo's Hot Dogs\", 'Quartino Ristorante', \"Pequod's Pizzeria\", 'Crisp', \"Joe's Seafood, Prime Steak & Stone Crab\", 'Xoco', \"Molly's Cupcakes\", 'Millennium Park']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\n",
    "`paginated_restaurant_search_requests`: returns a list of tuples for paginated search of all restaurants\n",
    "* args:\n",
    "  * api_key (string): yelp api key for Authentication\n",
    "  * location (string): business location\n",
    "  * total (int): total number of items to be fetched\n",
    "* returns:\n",
    "  * results (list): list of tuple (url, headers, url_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paginated_restaurant_search_requests(api_key, location, total):\n",
    "  \"\"\"\n",
    "  Returns a list of tuples (url, headers, url_params) for paginated search of all restaurants\n",
    "  Args:\n",
    "    api_key (string): Your Yelp API Key for Authentication\n",
    "    location (string): Business Location\n",
    "    total (int): Total number of items to be fetched\n",
    "  Returns:\n",
    "    results (list): list of tuple (url, headers, url_params)\n",
    "  \"\"\"\n",
    "  # HINT: Use total, offset and limit for pagination\n",
    "  # You can reuse function location_search_params(...)\n",
    "\n",
    "  pages = [] # add result to page\n",
    "\n",
    "  offset_ = 0\n",
    "  while offset_ < total:\n",
    "    url, headers, url_params = location_search_params(api_key, location, offset = offset_, limit = 20, categories = \"restaurants\")\n",
    "    pages.append((url, headers, url_params))\n",
    "    offset_ = offset_ + 20\n",
    "    time.sleep(.3)\n",
    "\n",
    "  return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.\n",
    "`all_restaurants`: construct the pagination requests for all the restaurants on yelp for a location\n",
    "* args:\n",
    "  * api_key (string): yelp api key for authentication\n",
    "  * location (string): business location\n",
    "* returns:\n",
    "  * results (list): list of dicts representing each restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_restaurants(api_key, location):\n",
    "  \n",
    "  # What keyword arguments should you pass to get first page of restaurants in Yelp\n",
    "  url, headers, url_params = location_search_params(api_key, location, offset = 0)\n",
    "  # \n",
    "  #response_json = api_get_request(url, headers, url_params)\n",
    "  response = requests.get(url, params = url_params, headers = headers)\n",
    "  content_json = response.json()  \n",
    "\n",
    "  total_items = content_json[\"total\"]\n",
    "\n",
    "  restaurant_pages = paginated_restaurant_search_requests(api_key, location, total_items)\n",
    "\n",
    "  # Use returned list of (url, headers, url_params) and function api_get_request \n",
    "  # to retrive all restaurants\n",
    "  # REMEMBER to pause slightly after each request.\n",
    "  result = []\n",
    "\n",
    "  for i in range(len(restaurant_pages)):\n",
    "    page = restaurant_pages[i]\n",
    "\n",
    "    url = page[0]\n",
    "    headers = page[1]\n",
    "    url_params = page[2]\n",
    "\n",
    "    response = requests.get(url, params = url_params, headers = headers)\n",
    "    content_json = response.json() \n",
    "    page_data = content_json['businesses']\n",
    "\n",
    "    for j in range(len(page_data)):\n",
    "      result.append(page_data[j])\n",
    "\n",
    "    time.sleep(.3)\n",
    "\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "['Greek Islands Restaurant', 'Meli Cafe & Juice Bar', 'Artopolis', 'Athena Greek Restaurant', 'Zeus Restaurant', 'Green Street Smoked Meats', 'Santorini', 'Mr Greek Gyros', \"Philly's Best\", 'Primos Chicago Pizza Pasta', 'Monteverde', 'J.P. Graziano Grocery', '9 Muses', 'Sepia', 'Sizzling Pot King', 'High Five Ramen', 'Dawali Jerusalem Kitchen', 'Green Street Local', 'Spectrum Bar and Grill', 'The Allis', \"Lou Mitchell's\", \"Nando's Peri-Peri\", 'Jubilee Juice & Grill', \"Formento's\", 'Taco Burrito King', 'Dine', 'Chicken & Farm Shop', 'H Mart - Chicago', 'The Madison Bar and Kitchen', 'Parlor Pizza Bar', 'Loop Juice', 'Blaze Pizza', 'M2 Cafe', 'Booze Box', 'El Che Steakhouse & Bar', 'Omakase Yume', 'Blackwood BBQ', 'Bandit', 'Morgan Street Cafe', \"Giordano's\", \"Nonna's Pizza & Sandwiches\", \"Vero's Caffe & Gelato\", 'Ciao! Cafe & Wine Lounge', 'Umami Burger - West Loop', 'Slightly Toasted', 'Sushi Pink', 'Rye Deli & Drink', 'Epic Burger', 'My Thai', 'Naansense', \"Hannah's Bretzel\", \"Nancy's Pizza\", 'Beggars Pizza', 'SGD Dubu So Gong Dong Tofu & Korean BBQ', 'Taco Lulú', 'Dylans Tavern & Grill', 'Trivoli Tavern', \"Wok N' Bao\", 'Naf Naf Grill', 'I Dream of Falafel', 'Oki Sushi', 'TenGoku Aburiya', \"Jimmy John's\", 'Stelios Bottles & Bites', 'Pockets', \"Jet's Pizza\", 'Yolk West Loop', 'Asadito', 'Klay Oven Kitchen', \"Bebe's Kosher Deli\", 'Freshii', \"Cafe L'ami\", 'K-Kitchen', 'Veggie Grill', 'Subway', 'Chipotle Mexican Grill', \"JoKeR's Cajun Kitchen\", 'Potbelly Sandwich Shop-Temporarily Offline', 'Corner Bakery', 'The Ruin Daily', \"Sang's Kitchen\", 'Potbelly Sandwich Shop', 'Five Guys', 'Izakaya yume', \"Domino's Pizza\", \"Jimmy John's\", 'Red Star Bar', 'Aodake Ramen', 'Great Steak', 'Downstate Donuts', 'Roti Modern Mediterranean', \"Sam's Crispy Chicken\", 'Krispy Rice', 'Burger King', 'Panera Bread', 'CLAUDIA', 'Hunan House', 'Baci Amore', 'West Loop Sushi', 'Spaketeria', 'Flik International', 'Cafe Italo', \"Harold's Chicken On Clinton\", 'Subway']\n"
     ]
    }
   ],
   "source": [
    "data = all_restaurants(api_key, 'Greektown, Chicago, IL')\n",
    "print(len(data))\n",
    "# 102\n",
    "print(list(map(lambda x:x['name'], data)))\n",
    "# ['Greek Islands Restaurant', 'Meli Cafe & Juice Bar', 'Artopolis', 'WJ Noodles', 'Athena Greek Restaurant', ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.\n",
    "`parse_api_response`: parse yelp api results to extract restaurant URLs\n",
    "* args:\n",
    "  * data (string): string of properly formatted JSON\n",
    "* returns:\n",
    "  * urls (list): list of URLs as strings from the input JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_api_response(data):\n",
    "\n",
    "  data_ = json.loads(data)\n",
    "  data_ = data_['businesses']\n",
    "\n",
    "  urls = []\n",
    "  for i in range(len(data_)):\n",
    "    temp = data_[i]\n",
    "    urls.append(temp['url'])\n",
    "\n",
    "  return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test `parse_api_response`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.yelp.com/biz/wildberry-pancakes-and-cafe-chicago-2?adjust_creative=680Jc2E_i5DwGD1xYXozpg&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=680Jc2E_i5DwGD1xYXozpg', 'https://www.yelp.com/biz/au-cheval-chicago?adjust_creative=680Jc2E_i5DwGD1xYXozpg&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=680Jc2E_i5DwGD1xYXozpg', 'https://www.yelp.com/biz/the-purple-pig-chicago?adjust_creative=680Jc2E_i5DwGD1xYXozpg&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=680Jc2E_i5DwGD1xYXozpg', 'https://www.yelp.com/biz/lou-malnatis-pizzeria-chicago?adjust_creative=680Jc2E_i5DwGD1xYXozpg&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=680Jc2E_i5DwGD1xYXozpg']\n"
     ]
    }
   ],
   "source": [
    "url, headers, url_params = location_search_params(api_key, \"Chicago\", offset=0)\n",
    "response = requests.get(url, params = url_params, headers = headers)\n",
    "response_json = response.json()\n",
    "\n",
    "response_str = json.dumps(response_json)\n",
    "parsed = parse_api_response(response_str)\n",
    "print(parsed[1:5])\n",
    "# ['https://www.yelp.com/biz/girl-and-the-goat-chicago?adjust_creative=ioqEYAcUhZO272qCIvxcVA....',\n",
    "#  'https://www.yelp.com/biz/wildberry-pancakes-and-cafe-chicago-2?adjust_creative=ioqEYAcUhZO272qCIvxcVA...',..]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Parse a Yelp restaurant Page using `BeautifulSoup`\n",
    "\n",
    "`parse_page`: parse the reviews on a single page of a restaurant\n",
    "* args:\n",
    "  * html (string): string of HTML corresponding to a yelp restaurant\n",
    "* returns:\n",
    "  * reviews_list (list): list of dicts corresponding to the extracted review info; review structure:\n",
    "    ```python\n",
    "    {\n",
    "      'author': str\n",
    "      'rating': float\n",
    "      'date': str ('yyyy-mm-dd')\n",
    "      'description': str\n",
    "    }\n",
    "    ```\n",
    "  * url_next (string): URL for the next page of reviews (or None if it is the last page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page(html):\n",
    "\n",
    "  soup = BeautifulSoup(html,'html.parser')\n",
    "  url_next = soup.find('link', rel='next')\n",
    "  if url_next:\n",
    "    url_next = url_next.get('href')\n",
    "  else:\n",
    "    url_next = None\n",
    "\n",
    "  reviews = soup.find_all('div', itemprop=\"review\")\n",
    "  reviews_list = []\n",
    "  #for r in reviews:\n",
    "    #reviews_list.append(r.find('p', itemprop=\"description\"))\n",
    "\n",
    "\n",
    "  for i in range(len(reviews)):\n",
    "    r = reviews[i]\n",
    "    author = r.find(itemprop='author')\n",
    "    author = author.attrs['content']\n",
    "    rating = r.find(itemprop='ratingValue')\n",
    "    rating = float(rating.attrs['content'])\n",
    "    date = r.find(itemprop='datePublished')\n",
    "    date = date.attrs['content']\n",
    "    description = r.find('p').text\n",
    "    #description = r.find(itemprop='description')\n",
    "    #description = description.attrs['p']\n",
    "    review = {'author': author, 'rating': rating, 'date': date, 'description': description}\n",
    "    reviews_list.append(review)\n",
    "\n",
    "  #return_val = (reviews_list, url_next)  \n",
    "\n",
    "  return reviews_list, url_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Extract all Yelp reviews for a Single Restaurant\n",
    "`extract_reviews`: retrieve all of the reviews for a single restaurant on yelp\n",
    "* args:\n",
    "  * url (string): yelp URL corresponding to the restaurant of interest\n",
    "  * html_fetcher (function): function that takes url and returns html status code and content\n",
    "* returns:\n",
    "  * reviews (list): list of dictionaries containing extracted review info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews(url, html_fetcher):\n",
    "  \n",
    "  code, html = html_fetcher(url) \n",
    "  #reviews = []\n",
    "  reviews, next_url = parse_page(html)\n",
    "  print(html[0:100])\n",
    "\n",
    "  while (next_url != None):\n",
    "    code, html = html_fetcher(next_url)\n",
    "    reviews_temp, next_url_temp = parse_page(html)\n",
    "    for r in reviews_temp:\n",
    "      reviews.append(r)\n",
    "    next_url = next_url_temp\n",
    "\n",
    "  return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `extract_reviews`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML>\n",
      "\n",
      "<!--[if lt IE 7 ]> <html xmlns:fb=\"http://www.facebook.com/2008/fbml\" class=\"ie6 ie\n",
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ab2019cd4e08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 40\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# {'author': 'Betsy F.', 'rating': '5.0', 'date': '2016-10-01', 'description': \"Authentic, incredible ... \" }\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#data = extract_reviews('https://www.yelp.com/biz/the-jibarito-stop-chicago-2?start=220', html_fetcher=retrieve_html)\n",
    "data = extract_reviews('https://www.yelp.com/biz/the-jibarito-stop-chicago-2?start=220', html_fetcher=retrieve_html)\n",
    "print(len(data))\n",
    "# 40\n",
    "print(data[0])\n",
    "# {'author': 'Betsy F.', 'rating': '5.0', 'date': '2016-10-01', 'description': \"Authentic, incredible ... \" }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
